{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 01:10:45.286838: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-28 01:10:45.286875: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "60000 10000\n",
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "<class 'numpy.uint8'>\n",
      "(28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 01:10:49.484668: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-28 01:10:49.484699: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-28 01:10:49.484720: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (morio-H87M-S01): /proc/driver/nvidia/version does not exist\n",
      "2022-08-28 01:10:49.488191: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) =tf.keras.datasets.mnist.load_data()\n",
    "print(train_images.shape,train_labels.shape)\n",
    "print(len(train_images),len(test_labels))\n",
    "sample = test_images[0]\n",
    "train_images = train_images.reshape((len(train_images),28,28,1))\n",
    "test_images = test_images.reshape((len(test_images),28,28,1))\n",
    "\n",
    "train_images,test_images = train_images.astype(\"float32\"),test_images.astype(\"float32\")\n",
    "print(train_images.shape,test_images.shape)\n",
    "print(type(train_labels[0]))\n",
    "print(sample.shape)\n",
    "buf = tf.image.encode_png(sample[:, :, tf.newaxis])\n",
    "tf.io.write_file(\"cnn/mnist_savedmodel/sample.png\", buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "class CNN(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(CNN,self).__init__()\n",
    "    self.conv1 = tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1))\n",
    "    self.maxpooling1 = tf.keras.layers.MaxPool2D((2,2))\n",
    "    self.conv2 = tf.keras.layers.Conv2D(64,(3,3),activation='relu')\n",
    "    self.maxpooling2 = tf.keras.layers.MaxPool2D((2,2))\n",
    "    self.conv3 = tf.keras.layers.Conv2D(64,(3,3),activation='relu')\n",
    "    self.flatten = tf.keras.layers.Flatten()\n",
    "    self.dens1 = tf.keras.layers.Dense(64,activation='relu')\n",
    "    self.dens2 = tf.keras.layers.Dense(10,activation='softmax')\n",
    "  \n",
    "  def call(self,x):\n",
    "    x = self.conv1(x)\n",
    "    x = self.maxpooling1(x)\n",
    "    x = self.conv2(x)\n",
    "    x = self.maxpooling2(x)\n",
    "    x = self.conv3(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.dens1(x)\n",
    "    return self.dens2(x)\n",
    "model = CNN()\n",
    "print(model.variables)\n",
    "print(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" model.compile(optimizer='adam',\\n              loss='sparse_categorical_crossentropy',\\n              metrics=['accuracy'])\\n\\nmodel.fit(train_images, train_labels, epochs=5) \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#損失関数\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "#最適化関数\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# 評価指標\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(x,y):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(x, training=True)\n",
    "    loss = loss_object(y, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(y, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, t):\n",
    "    test_predictions = model(x)\n",
    "    t_loss = loss_object(t, test_predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(t, test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(16, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 21:53:24.798596: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 188160000 exceeds 10% of free system memory.\n",
      "2022-08-26 21:53:24.915677: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 31360000 exceeds 10% of free system memory.\n",
      "2022-08-26 21:53:24.941043: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.uint8)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 21:53:25.454628: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-08-26 21:53:49.973307: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 31360000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2274152636528015, Accuracy: 94.82333374023438, test-Loss: 0.07201920449733734, test-Accuracy:97.73999786376953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 21:53:51.316140: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.14609336853027344, Accuracy: 96.43916320800781, test-Loss: 0.06203008443117142, test-Accuracy:98.04000091552734\n",
      "Epoch 3, Loss: 0.11503647267818451, Accuracy: 97.08333587646484, test-Loss: 0.06337379664182663, test-Accuracy:97.98332977294922\n",
      "Epoch 4, Loss: 0.09756989777088165, Accuracy: 97.47874450683594, test-Loss: 0.05750598385930061, test-Accuracy:98.17500305175781\n",
      "Epoch 5, Loss: 0.08602694422006607, Accuracy: 97.74066925048828, test-Loss: 0.05848097801208496, test-Accuracy:98.16999816894531\n",
      "Epoch 6, Loss: 0.07724744826555252, Accuracy: 97.9463882446289, test-Loss: 0.05675932765007019, test-Accuracy:98.2550048828125\n",
      "Epoch 7, Loss: 0.07077979296445847, Accuracy: 98.10452270507812, test-Loss: 0.05447050929069519, test-Accuracy:98.34285736083984\n",
      "Epoch 8, Loss: 0.06527946144342422, Accuracy: 98.23854064941406, test-Loss: 0.05328453704714775, test-Accuracy:98.41124725341797\n",
      "Epoch 9, Loss: 0.06079905107617378, Accuracy: 98.35610961914062, test-Loss: 0.05280643701553345, test-Accuracy:98.45222473144531\n",
      "Epoch 10, Loss: 0.057030096650123596, Accuracy: 98.44833374023438, test-Loss: 0.05216410756111145, test-Accuracy:98.50299835205078\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(32)\n",
    "print(train_ds)\n",
    "EPOCHS = 10\n",
    "\"\"\" for epoch in range(EPOCHS):\n",
    "  train_step(train_images,train_labels)\n",
    " \"\"\"\n",
    "for epoch in range(EPOCHS):\n",
    "  for images, labels in train_ds:\n",
    "    #print(images.shape)\n",
    "    #print(labels.shape)\n",
    "    train_step(images, labels) #学習\n",
    "\n",
    "  for test_images, test_labels in test_ds:\n",
    "    test_step(test_images, test_labels) #評価\n",
    "\n",
    "  template = 'Epoch {}, Loss: {}, Accuracy: {}, test-Loss: {}, test-Accuracy:{}'\n",
    "  print(template.format(epoch + 1,\n",
    "                          train_loss.result(),\n",
    "                          train_accuracy.result() * 100,\n",
    "                          test_loss.result(),\n",
    "                          test_accuracy.result()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12106/4137337769.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#確立として解釈できるように、ソフトマックスを介して出力タイプを変換\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#outputs = tf.keras.layers.Dense(10,name=\"output\")(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#確立として解釈できるように、ソフトマックスを介して出力タイプを変換\n",
    "inputs = tf.keras.Input((28,28,1),name=\"input\",dtype=tf.float32)\n",
    "outputs = model(inputs)\n",
    "#print(x)\n",
    "#outputs = tf.keras.layers.Dense(10,name=\"output\")(x)\n",
    "#print(outputs)\n",
    "#outputs = tf.keras.layers.Softmax(name=\"output\")(x)\n",
    "probability_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "print(test_images[:1, :, :][0].shape)\n",
    "with open(\"./cnn/expected_values.txt\", \"w\") as f:\n",
    "    values = probability_model(test_images[1:2, :, :])[0].numpy()\n",
    "    print(*values, sep=\", \", file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 21:57:39.906150: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn/mnist_savedmodel/assets\n"
     ]
    }
   ],
   "source": [
    "directory = \"cnn/mnist_savedmodel/\"\n",
    "tf.saved_model.save(probability_model, directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fb6d4786d6ba20ad0e4bc2be870871392251dd057e3655123e5afdf59ecc94f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
